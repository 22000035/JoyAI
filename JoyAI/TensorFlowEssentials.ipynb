{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlowEssentials.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idebtor/JoyAI/blob/master/JoyAI/TensorFlowEssentials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "61NsUFtAVtfm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NKRuH1TrV216",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Essentials\n",
        "\n",
        "Before implementing machine-learning algorithms, let's first get familiar with how to use TensorFlow.  This lesson covers some essential advantages of TensorFlow to convice you it is the machine-learning library of choice.\n",
        "\n",
        "Suppose you are a private business owner tracking the flow of sales for your products.  Your inventory consists of 1,000 items, and you represent each item's price in a vector called `prices`.  Another 1,000-dimensional vector called `amounts` represents the inventoroy count of each item.  Then you want to write a code to compute the revenue of selling all the products.  Keep in mind that this code does not import any libraries. \n"
      ]
    },
    {
      "metadata": {
        "id": "yRTKQW0WXSa-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d514246-5e52-4fa3-a999-6666e23e7e7c"
      },
      "cell_type": "code",
      "source": [
        "prices = [32.50, 10.5, 0.55, 2.5, 4.0]\n",
        "amounts = [10, 20, 5, 2, 3]\n",
        "\n",
        "revenue = 0\n",
        "for price, amount in zip(prices, amounts):\n",
        "  revenue += price * amount\n",
        "  \n",
        "print(revenue)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "554.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b1D4Bepdb503",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a lot of code just to calculate the inner (or dot) product of two vectors. The following code shows how to concisely write the same inner product using NumPy."
      ]
    },
    {
      "metadata": {
        "id": "cWMzAfl7Xg-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "adeff7fe-13d3-4590-8636-7bdc49fe958c"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "prices = np.array([32.50, 10.5, 0.55, 2.5, 4.0])\n",
        "amounts = np.array([10, 20, 5, 2, 3])\n",
        "\n",
        "revenue = np.dot(prices, amounts)\n",
        "  \n",
        "print(revenue)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "554.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oi0ViyHDcOpG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When we are using TensorFlow and NumPy libraries, we can simplify this kind of coding significantly.  Using Python without libraries is like using a camera without auto mode: you gain more flexibility, you can easily make careless mistakes.  It is easy to make mistakes in machine learning, so let's keep our camera on autofocus and use Tenforflow and NumPy to help autormate tedious software development.\n",
        "\n",
        "First, you import TensorFlow by running following script: "
      ]
    },
    {
      "metadata": {
        "id": "c9Ob0wCdY95_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YrshGHfkeZXk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you were able to run the cell above, then you are ready to work with TensorFlow.  Otherwise, you may need to install it first.\n",
        "\n",
        "\n",
        "## Representing tensors\n",
        "\n",
        "A convenient way to describe an object's in the real world is through listing its properties, or features.  For example, you can describe a car by its color, model, engine type, mileage, door style, and so on.  An ordered list of features is called __feature vector__, and that's exactly what you'll represent in TensorFlow code. \n",
        "\n",
        "Feature vectors are one of the most unseful devices in machine learning because of its simplicity (they're just a list of numbers).  Each data item typically consists of a feature vector, and good dataset has hundreds, if not thousands, of these feature vectors.  No doubt, you'll often be dealing with more than one vector at a time.  A matrix concisely represents a list of vectors, where each column of a matrix is a feature vector. \n",
        "\n",
        "The syntax to represent matrices in matrices in TensorFflow is a vector of vectors, each of the same length.   The following three lines of code  are trying to represent the same 2 x 2 matrix. "
      ]
    },
    {
      "metadata": {
        "id": "JEd01MYkeS5S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "364059e2-4542-495f-b5f7-630d71a3cae1"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Three ways of representing 2 x 2 tensors\n",
        "\n",
        "m1 = [[1.0, 2.0], \n",
        "      [3.0, 4.0]]\n",
        "\n",
        "m2 = np.array([[1.0, 2.0], \n",
        "               [3.0, 4.0]], dtype=np.float32) \n",
        "\n",
        "m3 = tf.constant([[1.0, 2.0], \n",
        "                  [3.9, 4.0]]) \n",
        "\n",
        "print(type(m1))\n",
        "print(type(m2))\n",
        "print(type(m3))\n",
        "\n",
        "t1 = tf.convert_to_tensor(m1, dtype=tf.float32)\n",
        "t2 = tf.convert_to_tensor(m2, dtype=tf.float32)\n",
        "t3 = tf.convert_to_tensor(m3, dtype=tf.float32)\n",
        "\n",
        "print(type(t1))\n",
        "print(type(t2))\n",
        "print(type(t3))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n",
            "<class 'tensorflow.python.framework.ops.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Np4yQVJgj9kw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first variable `m1` is a list, the second variable `m2` is an `ndarray` from the NumPy library, and the last variable `m3` is TensorFLow constant `Tensor` object that you initialized using `tf.constant`. "
      ]
    },
    {
      "metadata": {
        "id": "dIDj_Jt8rlht",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating tensors\n",
        "\n",
        "Let's take another look at defining tensor in code.  After importint the TensorFlow library, you can use the `tf.constant` operator as follows.  Here are a couple of tensors of various dimensions. "
      ]
    },
    {
      "metadata": {
        "id": "1_j2aaOAtPjN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "28e401f7-0a63-4fbe-afed-64ad135115b3"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "m1 = tf.constant([[1., 2.]])  # defines a 2 x 1 matrix\n",
        "\n",
        "m2 = tf.constant([[1], [2]])  # defines a 1 x 2 matrix\n",
        "\n",
        "m3 = tf.constant([[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11, 12]]])  \n",
        "\n",
        "print(m1)\n",
        "print(m2)\n",
        "print(m3)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_3:0\", shape=(1, 2), dtype=float32)\n",
            "Tensor(\"Const_4:0\", shape=(2, 1), dtype=int32)\n",
            "Tensor(\"Const_5:0\", shape=(2, 3, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wqZPl-IVuTdL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow also comes with a few convenient constructors for some simple tensors.  For example, `tf.zeros(shape)` creates a tensor with all  values initialized at zeroof a specific shape.  Similarly, `tf.zeros(shape)` creates a tensor of a specific shape with all values initialized at once.  The shape argument is a one-dimensional (1D) tensor of type `int32` (a list of integers) describing the dimensions of the tensor."
      ]
    },
    {
      "metadata": {
        "id": "Y7m2nZQ1xNjR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise 1\n",
        "Initialize a 500 x 500 tensor with all elements equaling 0.5.\n",
        "\n",
        "Answer:\n",
        "  tf.ones( [500, 500] ) * 0.5"
      ]
    },
    {
      "metadata": {
        "id": "3xuxDc0fxMeR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "howpkHcLvB4W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating operators\n",
        "\n",
        "Now that you have a few starting tensors ready to be used, you can apply more-interesting operators such as addition or multiplication.  Let's start simple aand run a negation op (short for _operation_) on the `m1` tensor from above.  \n",
        "\n",
        "#### Note\n",
        "_Defining_ an operation, such as negation, is different from _running_ it. So far, you've _defined_ how operation should behave.  In next section, you'll _evaluate_ (or _run_) them to compute their result. "
      ]
    },
    {
      "metadata": {
        "id": "BvQrYV18wPPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67da9eee-f4b6-4c9e-d533-ae5e6c44f240"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant([[1, 2]])\n",
        "neg_x = tf.negative(x)\n",
        "print(neg_x)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Neg:0\", shape=(1, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FlEuCqm-wsQk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that the output is not `[[-1, -2]]`.  That's because you're printing out the definition of the negation op, not the actual evaluation of the op.  \n",
        "\n",
        "Useful Tensorflow operators\n",
        "\n",
        "tf.add(x, y)\n",
        "\n",
        "tf.subtract(x, y)\n",
        "\n",
        "tf.multiply(x, y)\n",
        "\n",
        "tf.pow(x, y)\n",
        "\n",
        "tf.exp(x)\n",
        "\n",
        "tf.sqrt(x)\n",
        "\n",
        "tf.div(x, y)\n",
        "\n",
        "tf.truediv(x, y)\n",
        "\n",
        "tf.floordiv(x, y)\n",
        "\n",
        "tf.mod(x, y)"
      ]
    },
    {
      "metadata": {
        "id": "Zc9QnYSiycd9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercise 2\n",
        "\n",
        "Use the TensorFlow operators you've learned so far to produce the Gaussian distribution (also known as the normal distruction).  For reference, you can find the probability density of the normal distribution online:  https://en.wikipedia.org/wiki/Normal_distribution.\n",
        "\n",
        "### Answer \n",
        "Most mathematical expressions such as x, - +, and so on are just shortcuts for their TensorFlow equivalent, for brevity.  The Gaussian function includes many operations, so it is cleaner to use shorthand notations as follows:"
      ]
    },
    {
      "metadata": {
        "id": "fYQzz4chjxL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "946ee423-3566-4e65-bb24-c3525207f67c"
      },
      "cell_type": "code",
      "source": [
        "from math import pi\n",
        "x = 1\n",
        "mean = 0.0\n",
        "sigma = 1.0\n",
        "\n",
        "(tf.exp(tf.negative(tf.pow(x - mean, 2.0) / (2.0 * tf.pow(sigma, 2.0) ))) \n",
        "                   * (1.0 / (sigma * tf.sqrt(2.0 * pi) )))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'mul_3:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "jyPRjyFK5uST",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Executing operators with sessions\n",
        "\n",
        "A _session_ is an environment of a software system that describes how the lines of code should run.  In TensorFlow, a session sets up how the hardware devices (such as CPU and GPU) talks to each other. That way, you can design your machine-learning algorithm without worrying about micromanaging the hardware it runs on.  You can later configure the session to change its behavior without chaning a line of the machine learning code. \n",
        "\n",
        "To execute an operation and retrieve its calculated value, TensorFlow requires a session.  Only a registered session may fill the values of a `Tensor` object.  To do so, you must create a session class by using `tf.Session()` and tell it to run an operator, as shown in the following listing.  The result will be a value you can later use for further compuations."
      ]
    },
    {
      "metadata": {
        "id": "9QVhg0hDz4Z-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2719d4ab-39c8-4862-f263-9dc124b2b6c6"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant([[1., 2.]])\n",
        "neg_x = tf.negative(x)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  result = sess.run(neg_x)\n",
        "  \n",
        "print(result)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1. -2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xs0AV41g8dpB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Congratulations! \n",
        "\n",
        "You have just written your first full Tensorflow code.  A session notly configures _when_ your code will be computed on your machine, but also _how_ the computation will be laid out in order to parallelize computation.   Every `Tensor` object has an `eval()` function to evaluate the mathematical operations that define its value.  But the `eval()` function requires definind a session object for the library to understand how to best use the underlying hardware.  The listing shown above used `sess.run(...)`, which is equivalent to invoking the Tensor's `eval()` function in the context of the session. \n",
        "\n",
        "When you are running TensorFlow code through an interactive environment (for debugging or presentation purposes), it is often easier to create the session in interactive mode, where the session is implicityly part of any call to `eval()`.  That way, the session variable does not need to be passed around throughout the code, making it easier to focus on the relevant parts of the algorithm, as seen in the following listing.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "MtARUKIs7xNp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "x = tf.constant([[1., 2.]])\n",
        "neg_op = tf.negative(x)\n",
        "\n",
        "# Since we're using an interactive session, \n",
        "# we can just call the eval() method on the op.\n",
        "\n",
        "result = neg_op.eval()\n",
        "\n",
        "print(result)\n",
        "sess.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CWfgk4ps-oNV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "That code's a little cleaner when using Jupyter notebooks (like this one).  Don't forget to close the session:"
      ]
    },
    {
      "metadata": {
        "id": "8tVbYlTbB3mr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setting session configuration\n",
        "\n",
        "You can also pass options to `tf.Session`.  For example, TensorFlow automatically determines the best way to assign a GPU or CPU device to an operation depending on what's available.  You can pass adn additional option, `log_device_placements=True`, when creating a session, as shown in the following listing, which will show you exactly where on your hardware the compuations are evoked.  Try this from a terminal. Jupyter notebooks won't show the logging info.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "6vVyVXZ-C4eU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f733b301-58b1-4167-ff00-4a534baba9d0"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant([[1, 2]])\n",
        "neg_op = tf.negative(x)\n",
        "\n",
        "# Starts the session with a special config passed into the constructor\n",
        "# to enable logging\n",
        "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
        "    result = sess.run(neg_op)\n",
        "\n",
        "print(result)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1 -2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4F6nyeKODgZS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Three types of values\n",
        "\n",
        "Sessions are essential in TensorFlow code.  You need to call a session to __run__ the math.  A session not only runs a computational graph operation, but also can take placeholders, variables, and constants as input.  We've used constants so far, but in later sections, we will start using variables and placeholders.  Here's a quick overview of these three types of values:\n",
        "\n",
        "- Placehoders: A value that's unassigned but will be initialized by the session wherever it is run.  Typically, placeholders are the input and output of your model\n",
        "\n",
        "- Variable: A value that can change, such as parameters of a machine-learning model.  Variables must be initialized by the session before they're used\n",
        "\n",
        "- Constant: A value that does not change, such as hyperparameters or settings.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nESQYqSBGLiE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using variables\n",
        "\n",
        "Finding the equation of a line that best fits many points is a classic machine-learning problem.  The algorithm starts with an initial guess, which is an equation characterized by a few numbers (such as the slope or y-intercept). Over time, the algorithm generates increasingly better guesses for these numbers, which are also called _parameters_.\n",
        "\n",
        "So far, we've seen manipulating only constants. Programs with only constants are not that interesting for real-world applications, so TensorFlow allows richer tools such as variables, which are containers for values that may change over time.  A machine=learning algorithm updates the parameters of a model until it finds the optimal value for each variable.  In the world of machine learning, it is common for parameters to fluctuate until eventually settling down, making variables an excellent data structure for them. \n",
        "\n",
        "The code shown below is a simple TensorFlow program that demonstrates how to use variables.  It updates a variable whenever sequential data abruptly increases in value.  Think about recoding measurements of a neuron's activity over time. This piece of code can detect when the neuron's activity suddenly spickes.  Of course the algorithm is oversimplication for diabetic purposes.\n",
        "\n",
        "-------------------\n"
      ]
    },
    {
      "metadata": {
        "id": "Dqq5qUoqI-2Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we go, here we go, here we go! Moving on from those simple examples, let's get a better understanding of variables. Start with a session:"
      ]
    },
    {
      "metadata": {
        "id": "MSG0EM3mDCKM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuvPZeMoJDxC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below is a series of numbers. Don't worry what they mean. Just for fun, let's think of them as neural activations."
      ]
    },
    {
      "metadata": {
        "id": "7EzugVXVJGqU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raw_data = [1., 2., 8., -1., 0., 5.5, 6., 13]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Fyn4KH4JI5n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a boolean variable called `spike` to detect a sudden increase in the values.\n",
        "\n",
        "All variables must be initialized. Go ahead and initialize the variable by calling `run()` on its `initializer`:"
      ]
    },
    {
      "metadata": {
        "id": "dxfiNDLEJML_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "spike = tf.Variable(False)\n",
        "spike.initializer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dtrV1E18JP4L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loop through the data and update the spike variable when there is a significant increase:"
      ]
    },
    {
      "metadata": {
        "id": "SbOdPz2HJSEU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(1, len(raw_data)):\n",
        "    if raw_data[i] - raw_data[i-1] > 5:\n",
        "        updater = tf.assign(spike, tf.constant(True))\n",
        "        updater.eval()\n",
        "    else:\n",
        "        tf.assign(spike, False).eval()\n",
        "    print(\"Spike\", spike.eval())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwKxPbXfJVNs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You forgot to close the session! Here, let me do it:"
      ]
    },
    {
      "metadata": {
        "id": "mK3v5JnTJZj-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JIzRixPhEEIU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow allows you to declare a session by using `tf.InteractiveSession()`. When you've declared an interactive session, TensorFlow functions don't require the session attribute they would  otherwise, which makes coding in Jupyter Notebooks easier.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "6FvV3TVsLuFR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Saving and loading variables\n",
        "\n",
        "Imagine writing a monolithic block of code, of which you'd like to individually test a tiny segment.  In complicated machine-learning situations, saving and loading data at known checkpoints makes it much easier to debug code.  TensorFlow provides an elegant interface to save and load variable values to disk;  let's see how to use it for that purpose.\n",
        "\n",
        "Let's revamp the code that you created in list above to save the spike data to disk so you can load it elsewhere.  You'll change the history of spikes.  Notice that you will explicitly name the variables so they can be loaded later with the same name.  Naming a variable is optional but highly encouraged to organize your code.  \n",
        "\n",
        "Try running this code to see the results."
      ]
    },
    {
      "metadata": {
        "id": "kSaguHuXNFGl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving variables"
      ]
    },
    {
      "metadata": {
        "id": "OhsAjo-iM8N-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "b3f553ac-9f27-4d5a-821e-228ec524bd99"
      },
      "cell_type": "code",
      "source": [
        "# Create an interactive session and initialize a variable:\n",
        "import tensorflow as tf\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# Let's say you have a series of data like this\n",
        "raw_data = [1., 2., 8., -1., 0., 5.5, 6., 13]\n",
        "spikes = tf.Variable([False] * len(raw_data), name='spikes')\n",
        "spikes.initializer.run()   # initialize the variable\n",
        "\n",
        "# The saver op will enable saving and restoring:\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# Loop through the data and update the spike variable when there is a significant increase:\n",
        "for i in range(1, len(raw_data)):\n",
        "    if raw_data[i] - raw_data[i-1] > 5:\n",
        "        spikes_val = spikes.eval()\n",
        "        spikes_val[i] = True\n",
        "        # updates the value of spikes by susing the assign function\n",
        "        updater = tf.assign(spikes, spikes_val)\n",
        "        # not to forget this, otherwise, spikes won't be updated\n",
        "        updater.eval()\n",
        "        \n",
        "#Now, save your variable to disk!\n",
        "save_path = saver.save(sess, \"./spikes.ckpt\")\n",
        "print(\"spikes data saved in file: %s\" % save_path)\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "spikes data saved in file: ./spikes.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KO1uCilXRKgY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You'll notice a couple of files generated, one of them being `spikes.ckpt`, in the same folder as your source code.  It's a compactly stored binary file, so you can't easily modify it with a text editor.  To retrieve this data, you can use the `restore` function from the `saver` op, as demonstrated in the following listing. "
      ]
    },
    {
      "metadata": {
        "id": "PM5xF8WbPL2V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading variables\n"
      ]
    },
    {
      "metadata": {
        "id": "6OD0VAHRNRLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "930cd3be-f193-4912-cfe3-4cbbf90dec29"
      },
      "cell_type": "code",
      "source": [
        "# This one's about loading what you saved. Start by creating an interactive session:\n",
        "\n",
        "import tensorflow as tf\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# Create a boolean vector called spikes of the same dimensions as before:\n",
        "spikes = tf.Variable([False]*8, name='spikes')\n",
        "\n",
        "# Restored the variable data from disk, serve warm, and enjoy:\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "try:\n",
        "    saver.restore(sess, 'spikes.ckpt')\n",
        "    print(spikes.eval())\n",
        "except:\n",
        "    print('file not found')\n",
        "sess.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from spikes.ckpt\n",
            "file not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pP0Fmev-Sn4I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualizing data using TensorBoard\n",
        "\n",
        "In machine-learning, the most time-consuming part isn't programming, but it is waiting for code to finish running.  For example, a famous dataset called ImageNet contains over 14 million images prepared to be used in a machine-learning context.  Sometimes it can take up to days or weeks to finish training an algorithm using a large dataset.  TensorFlow's handy dashboard, TensorBoard, affords you a quick peek into the way values are changing in each node of the computational graph, giving you some idea of how your code is performing. \n",
        "\n",
        "Let's see how to visualized variable trends over time in a real-world example.  In this session, you will implement a moving-average algorithm in TensorFlow, add then you will carefully track the variables you care about for visualization in TensorBoard.\n",
        "\n",
        "## 1. Implementing a moving average\n",
        "Let us use TensorBoard to visualize how data changes.  Suppose you are interested in calculating the average stock price of a company.  Typically, computing the average is just a matter of adding up all the values and dividing by the total number seen: $ mean = (x_1 + x_2 + ... + x_n) / n$.  When the total number of values is unknown., you can use a technique called _exponential averaging__ to estimate the average value of an unknown number of data points.  The exponential average algorithm calculates the current estimated average as a function of the previous estimated average and current value. \n",
        "\n",
        "More succinctly, $Avg_t = f(Avg_{t-1}, x_t) = (1 - \\alpha) Avg_{t-1} + \\alpha x_t$.  Alpha($\\alpha$) is a parameter that will be turned, representing how strongly recent values should be biased in the calculation of the average.  The higher the value of $\\alpha$, the more dramatically the calculated acerage will differ from the previously estimated average.  \n",
        "\n",
        "When you code this, it is a good idea to think about the main piece of computation that takes place in each iteration. In this case, each iteration will compute $Avg_t = (1 - \\alpha)Avg_{t-1} + \\alpha x_t$. As a result, you can design a TensorFlow operator that does exactly as the formula says as listed below:\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nHDCv9JsSnM6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "update_avg = alpha * curr_value + (1 - alpha) * prev_avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pbgd4jQCZ2iu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To run this code, you will have to eventually define `alpha`, `curr_value`, and `prev_avg`.\n",
        "\n",
        "You'll define the undefined variables later.  The reason you're writing code in such a backward way is that defining the interface first forces you to implement the peripheral setup code to satisfy the interface.  \n",
        "\n",
        "Skipping ahead, let us jump right to the session part to see how your algorithm should behave.  The following listing sets up the primary loop and calls the `update_avg` operator on each iteration.  Running the `update_avg` operator depends on the `curr_value`, which is fed using the `feed_dict` argument. \n"
      ]
    },
    {
      "metadata": {
        "id": "thzJTtV_STqz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raw_data = np.random.normal(10, 1, 100)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  for i in range(len(raw_data))\n",
        "    curr_avg = sess.run(update_avg, feed_dict={curr_value: raw_data[i]})\n",
        "    sess.run(tf.assign(prev_avg, curr_avg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pW0ekAwnbjDz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Great, the general picture is clear, because all that is left to do is to write out the undefined variables.  Let's fill in the gaps and implement a working piece of TensorFlow code.  Copy the following listing so you can run it."
      ]
    },
    {
      "metadata": {
        "id": "jzz-f6hucDT_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "raw_data = np.random.normal(10, 1, 100)  # 100 numbers with mean=10, std=1\n",
        "\n",
        "alpha = tf.constant(0.05)                # alpha is set as a constant\n",
        "curr_value = tf.placeholder(tf.float32)  # the value is injected from the session\n",
        "prev_avg = tf.Variable(0.)               # pre_avg is set to 0\n",
        "update_avg = alpha * curr_value + (1 - alpha) * prev_avg\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    # loops through the data one by one to update the average\n",
        "    for i in range(len(raw_data)):\n",
        "        curr_avg = sess.run(update_avg, feed_dict={curr_value: raw_data[i]})\n",
        "        sess.run(tf.assign(prev_avg, curr_avg))\n",
        "        print(raw_data[i], curr_avg)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H9mzjYysc_o1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A placehoder is just like a variable, but the value is injected from the session.  "
      ]
    },
    {
      "metadata": {
        "id": "u6NfevsKeBWk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Visualizing the moving average\n",
        "\n",
        "Now that you have a working implementation of a moving-average algorithm, let us visualize the results by using TensorBorad. Visualization using TensorBoard is usually a two-step process:\n",
        "\n",
        "1. Pick out which nodes you care about measuring by annotating them with a _summary op_.\n",
        "\n",
        "2. Call _add_summary_ on them to queue up data to be written to disk.\n",
        "\n",
        "For example, let's say you have an `img` placeholder and a `cost` op, as shown in the following listing.  You can annotate them (by giving each a name such as `img` or `cost`) so that they are capable of being visualized in TensorBord.  You will do something similar with your moving-average example. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "OqtY8ZN2fIFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Annotating with a summary op\n",
        "\n",
        "img = tf.placeholder(tf.float32, [None, None, None, 3])\n",
        "cost = tf.reduce_sum(...)\n",
        "\n",
        "my_img_summary = tf.summary_image(\"img\", img)\n",
        "my_cost_summary = tf.summary_scalar(\"cost\", cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wllq2JvnfmFt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "More generally, to communicate with TensorBoard, you must use a summary op, which produces serialized strings used by a `SummaryWirte` to save updates to a dictionary.  Every time you call the `add_summary` method from `SummaryWriter`, TensorFlow will save data to disk for TensorBoard to use.  \n",
        "\n",
        "__Warning__ Be careful not to call the `add_summary` function too often!  Although doing so will produce higher-resolution visualizations of your variables, it will be at the cost of more computation and slightly slower learning. \n",
        "\n",
        "Run the following command to make a directory called logs in the same folder as this source code: \n",
        "\n",
        "```\n",
        "$ mkdir logs\n",
        "```\n",
        "\n",
        "Run TensorBoard with the location of the logs directory passed in as an argument:\n",
        "\n",
        "```\n",
        "$tensorboard --logdir=./logs\n",
        "```\n",
        "\n",
        "Open a browser and navigate to http://localhost:6006, which is the default URL for TensorBoard.  The following listing shows how to hook up the `SummaryWriter` to your code.  \n",
        "\n",
        "Run it and refresh the TensorBoard to see the visulaization.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nfJaD2FwhRfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1817
        },
        "outputId": "1de443ed-93f4-4969-8428-2d00b256dfb4"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "raw_data = np.random.normal(10, 1, 100)  # 100 numbers with mean=10, std=1\n",
        "\n",
        "alpha = tf.constant(0.05)                # alpha is set as a constant\n",
        "curr_value = tf.placeholder(tf.float32)  # the value is injected from the session\n",
        "prev_avg = tf.Variable(0.)               # pre_avg is set to 0\n",
        "update_avg = alpha * curr_value + (1 - alpha) * prev_avg\n",
        "\n",
        "# Here's what we care to visualize:\n",
        "avg_hist = tf.summary.scalar(\"running_average\", update_avg)\n",
        "value_hist = tf.summary.scalar(\"incoming_values\", curr_value)\n",
        "\n",
        "merged = tf.summary.merge_all()\n",
        "writer = tf.summary.FileWriter(\"./logs\")\n",
        "\n",
        "# Time to compute the moving averages. \n",
        "# We'll also run the merged op to track how the values change:\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    sess.add_graph(sess.graph)  # Optional, to visualize the computation grpah in TB\n",
        "    # loops through the data one by one to update the average\n",
        "    for i in range(len(raw_data)):\n",
        "        summary_str, curr_avg = sess.run([merged, update_avg], feed_dict={curr_value: raw_data[i]})\n",
        "        sess.run(tf.assign(prev_avg, curr_avg))\n",
        "        print(raw_data[i], curr_avg)\n",
        "        writer.add_summary(summary_str, i)\n",
        "        \n",
        "#made the logs be written successfully\n",
        "writer.close()\n",
        "        \n",
        "# Check out the visualization by running TensorBoard from the terminal:\n",
        "# $ tensorboard --logdir=path/to/logs"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.031713614563586 0.5515857\n",
            "8.594751436163037 0.95374393\n",
            "9.501471492616439 1.3811302\n",
            "7.213976043191696 1.6727725\n",
            "9.123005517524557 2.0452843\n",
            "9.889314459403518 2.4374857\n",
            "8.603888738513648 2.7458057\n",
            "9.77934495800814 3.0974827\n",
            "10.374639990158546 3.4613407\n",
            "8.972789104779812 3.736913\n",
            "8.177305597191756 3.9589324\n",
            "10.37410908684204 4.279691\n",
            "10.435739027862624 4.587494\n",
            "10.124557043726899 4.864347\n",
            "11.064879096116853 5.1743736\n",
            "10.178585590050705 5.424584\n",
            "9.324313430268532 5.6195703\n",
            "11.536514746807859 5.915417\n",
            "10.070162495533383 6.123154\n",
            "9.377744565893094 6.285884\n",
            "8.693748504574762 6.406277\n",
            "9.943695952620773 6.583148\n",
            "9.435991514506979 6.72579\n",
            "11.060073999059288 6.9425044\n",
            "8.551051788092513 7.0229316\n",
            "8.178646861697453 7.080717\n",
            "11.616381173288437 7.3075004\n",
            "10.225569293654445 7.453404\n",
            "10.97077272092606 7.6292725\n",
            "11.065264122244777 7.801072\n",
            "10.958863840460715 7.9589615\n",
            "10.543673049112206 8.088197\n",
            "10.137202324879905 8.190647\n",
            "8.608945279506145 8.211562\n",
            "8.450986218021768 8.223534\n",
            "10.753733256490289 8.350043\n",
            "10.02182967263624 8.433632\n",
            "8.485598428256795 8.436231\n",
            "7.724651048646461 8.400651\n",
            "8.606746995477032 8.410955\n",
            "10.723838932289423 8.5266\n",
            "10.950423007131981 8.647791\n",
            "10.297109001068526 8.730257\n",
            "10.5811096970906 8.8228\n",
            "9.60870642232805 8.862095\n",
            "9.909508550247871 8.914466\n",
            "8.919122766904891 8.914699\n",
            "10.346324466563965 8.9862795\n",
            "10.440565043675553 9.058993\n",
            "10.50184930425203 9.131136\n",
            "10.410574847064181 9.195107\n",
            "11.525625241310296 9.311633\n",
            "8.856801200621833 9.288891\n",
            "10.057079572144657 9.3273\n",
            "9.421870846119626 9.332028\n",
            "8.769906954526943 9.303923\n",
            "8.235734466662718 9.250513\n",
            "11.136848889357717 9.3448305\n",
            "9.250336539105058 9.340106\n",
            "8.88271216022219 9.317236\n",
            "10.247236016890593 9.363735\n",
            "10.655402103140013 9.428318\n",
            "10.72694186674255 9.493249\n",
            "10.63074201418317 9.550123\n",
            "9.311360804806716 9.538184\n",
            "8.338280848695799 9.4781885\n",
            "9.08467299265856 9.458513\n",
            "9.695721414670164 9.470373\n",
            "12.176676970968257 9.605689\n",
            "8.8546103875884 9.568135\n",
            "11.320024234081759 9.655729\n",
            "9.181284522599126 9.632008\n",
            "10.06446536695381 9.65363\n",
            "10.913920109158447 9.716645\n",
            "10.135604154051299 9.737594\n",
            "11.314452110794987 9.816437\n",
            "11.467781664269417 9.899004\n",
            "9.241286086894602 9.866118\n",
            "9.864565425689628 9.86604\n",
            "9.977764017660844 9.871626\n",
            "10.973125859522572 9.926701\n",
            "10.204901125517472 9.940611\n",
            "10.40137733987148 9.96365\n",
            "9.947351970773589 9.962835\n",
            "10.138588023669444 9.971622\n",
            "10.306973905704176 9.98839\n",
            "10.93278845163828 10.03561\n",
            "9.530299763680082 10.0103445\n",
            "10.302888198806144 10.024972\n",
            "9.069753577308022 9.977211\n",
            "9.723008014076331 9.964501\n",
            "8.715722194621012 9.902062\n",
            "10.811899672871268 9.947555\n",
            "8.600082416492665 9.880181\n",
            "10.841654283531241 9.928255\n",
            "9.064802696080488 9.885082\n",
            "9.331480067577056 9.857402\n",
            "10.803534243926599 9.904708\n",
            "10.011561852528205 9.91005\n",
            "10.152682195988527 9.922182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HXE9-i0uigFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}