{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Note: Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anaconda를 설치한 후, Tensorflow 설치하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "관리자 권한으로 Windows cmd 혹은 powershell을 시작합니다. Mac에서는 terminal을 시작합니다. \n",
    "\n",
    "1. 다음 명령어로 파이썬 버전을 확인합니다. \n",
    "\n",
    "```\n",
    "   python --version \n",
    "   \n",
    "   (Python 3.7.1 출력된다면, Python 3.7 버전입니다)\n",
    "```\n",
    "   \n",
    "\n",
    "2. pip를 upgrade합니다. \n",
    "\n",
    "```\n",
    "    python -m pip install --upgrade pip\n",
    "```    \n",
    "    \n",
    "3. conda를 이용하여 tensorflow라는 가상환경(virtual environment)를 만듭니다. \n",
    "\n",
    "```\n",
    "    conda create -n tensorflow python=3.7\n",
    "```    \n",
    "    \n",
    "4. 위에서 만든 tensorflow 가상환경을 활성화합니다. \n",
    "\n",
    "```\n",
    "    activate tensorflow\n",
    "```    \n",
    "    \n",
    "5. 활성화된 tensorflow 가상환경에 tensorflow를 설치합니다. \n",
    "\n",
    "```\n",
    "    pip install tensorflow\n",
    "```    \n",
    "\n",
    "6. 이제 콘솔 창에서 tensorflow 설치를 확인합니다. Python을 시작하여, tensorflow를 import 하고, 버전을 확인하면 됩니다. \n",
    "\n",
    "```\n",
    "   python\n",
    "   import tensorflow as tf\n",
    "   print(tf.__version__)\n",
    "   exit()\n",
    "```   \n",
    "\n",
    "참고로, keras도 pip를 이용하여 다음과 같이 설치할 수 있습니다. \n",
    "\n",
    "    pip install keras\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mathScore = [85, 80, 84, 97, 92]\n",
    "englScore = [90, 77, 86, 92, 90]\n",
    "\n",
    "a = tf.placeholder(dtype=tf.float32)\n",
    "b = tf.placeholder(dtype=tf.float32)\n",
    "y = (a + b) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(y, feed_dict={a: mathScore, b:englScore})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Functions\n",
    "\n",
    "- tf.add\n",
    "- tf.subtract\n",
    "- tf.multiply\n",
    "- tf.truediv\n",
    "- tf.mod\n",
    "- tf.abs\n",
    "- tf.negative\n",
    "- tf.sign\n",
    "- tf.square\n",
    "- tf.sqrt\n",
    "- tf.pow\n",
    "- tf.maximum\n",
    "- tf.minimum\n",
    "- tf.exp\n",
    "- tf.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(7)\n",
    "b = tf.constant(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "c =  tf.add(a, b)\n",
    "sess.run(c)\n",
    "\n",
    "c = tf.subtract(a, b)\n",
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c =  tf.add(a, b)\n",
    "print(sess.run(c))\n",
    "\n",
    "c = tf.subtract(a, b)\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Session()\n",
    "\n",
    "아래 예제에서 c는 a 와 b를 더하는 연산을 정의한 tensor 그 자체라는 것이다. 이렇게 정의된 연산을 수행하기 위해, a와 b에 데이터를 넣고, 흐름이 일어나도록 하는 동작이 Session이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(11.5)\n",
    "b = tf.constant(7.2)\n",
    "c = tf.add(a, b)     # c is a tensor type\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering (군집화) Algorithm\n",
    "\n",
    "0. 무작위 중심(Centroid)값을 선택합니다. \n",
    "1. 중심에 가까운 데이터를 클러스터에 포함시킵니다.\n",
    "2. 중심을 클러스터 중앙으로 이동시킵니다.\n",
    "\n",
    "마지막 두 과정을 반복하면서 더 이상 중심의 위치가 변하지 않을 때까지 반복합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['x', 'y'])\n",
    "df.loc[0] = [2, 3]\n",
    "df.loc[1] = [2, 11]\n",
    "df.loc[2] = [2, 18]\n",
    "df.loc[3] = [4, 5]\n",
    "df.loc[4] = [4, 7]\n",
    "df.loc[5] = [5, 3]\n",
    "df.loc[6] = [5, 15]\n",
    "df.loc[7] = [6, 6]\n",
    "df.loc[8] = [6, 8]\n",
    "df.loc[9] = [6, 9]\n",
    "df.loc[10] = [7, 3]\n",
    "df.loc[11] = [7, 4]\n",
    "df.loc[12] = [7, 5]\n",
    "df.loc[13] = [7, 15]\n",
    "df.loc[14] = [7, 17]\n",
    "df.loc[15] = [8, 5]\n",
    "df.loc[16] = [8, 4]\n",
    "df.loc[17] = [9, 10]\n",
    "df.loc[18] = [9, 11]\n",
    "df.loc[19] = [9, 15]\n",
    "df.loc[20] = [9, 19]\n",
    "df.loc[21] = [10, 4]\n",
    "df.loc[22] = [10, 8]\n",
    "df.loc[23] = [10, 15]\n",
    "df.loc[24] = [12, 6]\n",
    "df.loc[25] = [13, 15]\n",
    "df.loc[26] = [14, 11]\n",
    "df.loc[27] = [15, 6]\n",
    "df.loc[28] = [15, 18]\n",
    "df.loc[29] = [19, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lmplot('x', 'y', data=df, fit_reg=False, scatter_kws={\"s\": 100})\n",
    "plt.title('K-means Example')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = df.values\n",
    "kmeans = KMeans(n_clusters = 4).fit(points)\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = kmeans.labels_\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lmplot('x', 'y', data=df, fit_reg=False, scatter_kws={\"s\": 150}, hue=\"cluster\")\n",
    "plt.title('K-means Example')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝 예제\n",
    "\n",
    "## 프로젝트 개요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "\n",
    "model = tf.global_variables_initializer();\n",
    "\n",
    "data = read_csv('../dataset/price data.csv', sep=',')\n",
    "\n",
    "xy = np.array(data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0100100e+07 -4.9000001e+00 -1.1000000e+01  8.9999998e-01\n",
      "   0.0000000e+00  2.1230000e+03]\n",
      " [ 2.0100102e+07 -3.0999999e+00 -5.5000000e+00  5.5000000e+00\n",
      "   8.0000001e-01  2.1230000e+03]\n",
      " [ 2.0100104e+07 -2.9000001e+00 -6.9000001e+00  1.4000000e+00\n",
      "   0.0000000e+00  2.1230000e+03]\n",
      " ...\n",
      " [ 2.0171228e+07  2.9000001e+00 -2.0999999e+00  8.0000000e+00\n",
      "   0.0000000e+00  2.9010000e+03]\n",
      " [ 2.0171230e+07  2.9000001e+00 -1.6000000e+00  7.0999999e+00\n",
      "   6.0000002e-01  2.9010000e+03]\n",
      " [ 2.0171232e+07  2.0999999e+00 -2.0000000e+00  5.8000002e+00\n",
      "   4.0000001e-01  2.9010000e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = xy[:, 1:-1]        # 4개의 변인을 입력을 받습니다.\n",
    "y_data = xy[:, [-1]]        # 가격 값을 입력 받습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 4])   # setting placeholder\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X, W) + b                   # 가설을 설정합니다.\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))   # 비용 함수를 설정합니다.\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.000005) # 최적화 함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0  손실 비용:  12808135.0\n",
      "- 배추 가격:  [3.8152833]\n",
      "# 500  손실 비용:  4199597.0\n",
      "- 배추 가격:  [-281.2415]\n",
      "# 1000  손실 비용:  3792055.2\n",
      "- 배추 가격:  [29.072697]\n",
      "# 1500  손실 비용:  3473658.5\n",
      "- 배추 가격:  [311.8733]\n",
      "# 2000  손실 비용:  3223181.0\n",
      "- 배추 가격:  [563.1376]\n",
      "# 2500  손실 비용:  3025672.0\n",
      "- 배추 가격:  [786.37524]\n",
      "# 3000  손실 비용:  2869694.0\n",
      "- 배추 가격:  [984.76483]\n",
      "# 3500  손실 비용:  2746387.0\n",
      "- 배추 가격:  [1161.1111]\n",
      "# 4000  손실 비용:  2648838.2\n",
      "- 배추 가격:  [1317.89]\n",
      "# 4500  손실 비용:  2571625.8\n",
      "- 배추 가격:  [1457.2919]\n",
      "# 5000  손실 비용:  2510482.0\n",
      "- 배추 가격:  [1581.2568]\n",
      "# 5500  손실 비용:  2462044.2\n",
      "- 배추 가격:  [1691.5033]\n",
      "# 6000  손실 비용:  2423655.5\n",
      "- 배추 가격:  [1789.5577]\n",
      "# 6500  손실 비용:  2393217.2\n",
      "- 배추 가격:  [1876.773]\n",
      "# 7000  손실 비용:  2369068.8\n",
      "- 배추 가격:  [1954.351]\n",
      "# 7500  손실 비용:  2349898.2\n",
      "- 배추 가격:  [2023.3594]\n",
      "# 8000  손실 비용:  2334666.0\n",
      "- 배추 가격:  [2084.7476]\n",
      "# 8500  손실 비용:  2322551.8\n",
      "- 배추 가격:  [2139.3572]\n",
      "# 9000  손실 비용:  2312904.2\n",
      "- 배추 가격:  [2187.9387]\n",
      "# 9500  손실 비용:  2305209.5\n",
      "- 배추 가격:  [2231.1582]\n",
      "# 10000  손실 비용:  2299059.2\n",
      "- 배추 가격:  [2269.6084]\n",
      "# 10500  손실 비용:  2294132.5\n",
      "- 배추 가격:  [2303.8162]\n",
      "# 11000  손실 비용:  2290174.0\n",
      "- 배추 가격:  [2334.2502]\n",
      "# 11500  손실 비용:  2286981.2\n",
      "- 배추 가격:  [2361.327]\n",
      "# 12000  손실 비용:  2284395.0\n",
      "- 배추 가격:  [2385.4177]\n",
      "# 12500  손실 비용:  2282288.8\n",
      "- 배추 가격:  [2406.852]\n",
      "# 13000  손실 비용:  2280561.2\n",
      "- 배추 가격:  [2425.9233]\n",
      "# 13500  손실 비용:  2279135.8\n",
      "- 배추 가격:  [2442.892]\n",
      "# 14000  손실 비용:  2277947.5\n",
      "- 배추 가격:  [2457.9905]\n",
      "# 14500  손실 비용:  2276948.8\n",
      "- 배추 가격:  [2471.4253]\n",
      "# 15000  손실 비용:  2276097.8\n",
      "- 배추 가격:  [2483.3801]\n",
      "# 15500  손실 비용:  2275365.2\n",
      "- 배추 가격:  [2494.018]\n",
      "# 16000  손실 비용:  2274726.2\n",
      "- 배추 가격:  [2503.484]\n",
      "# 16500  손실 비용:  2274161.5\n",
      "- 배추 가격:  [2511.9084]\n",
      "# 17000  손실 비용:  2273655.2\n",
      "- 배추 가격:  [2519.4058]\n",
      "# 17500  손실 비용:  2273195.8\n",
      "- 배추 가격:  [2526.0789]\n",
      "# 18000  손실 비용:  2272773.0\n",
      "- 배추 가격:  [2532.0173]\n",
      "# 18500  손실 비용:  2272378.8\n",
      "- 배추 가격:  [2537.3022]\n",
      "# 19000  손실 비용:  2272008.2\n",
      "- 배추 가격:  [2542.0083]\n",
      "# 19500  손실 비용:  2271655.8\n",
      "- 배추 가격:  [2546.196]\n",
      "# 20000  손실 비용:  2271318.5\n",
      "- 배추 가격:  [2549.9248]\n",
      "# 20500  손실 비용:  2270992.0\n",
      "- 배추 가격:  [2553.2454]\n",
      "# 21000  손실 비용:  2270675.5\n",
      "- 배추 가격:  [2556.202]\n",
      "# 21500  손실 비용:  2270365.5\n",
      "- 배추 가격:  [2558.8335]\n",
      "# 22000  손실 비용:  2270062.0\n",
      "- 배추 가격:  [2561.1782]\n",
      "# 22500  손실 비용:  2269763.0\n",
      "- 배추 가격:  [2563.2642]\n",
      "# 23000  손실 비용:  2269467.2\n",
      "- 배추 가격:  [2565.1274]\n",
      "# 23500  손실 비용:  2269175.5\n",
      "- 배추 가격:  [2566.7817]\n",
      "# 24000  손실 비용:  2268885.0\n",
      "- 배추 가격:  [2568.2578]\n",
      "# 24500  손실 비용:  2268597.2\n",
      "- 배추 가격:  [2569.5747]\n",
      "# 25000  손실 비용:  2268310.8\n",
      "- 배추 가격:  [2570.7476]\n",
      "# 25500  손실 비용:  2268025.0\n",
      "- 배추 가격:  [2571.7932]\n",
      "# 26000  손실 비용:  2267741.5\n",
      "- 배추 가격:  [2572.7295]\n",
      "# 26500  손실 비용:  2267458.5\n",
      "- 배추 가격:  [2573.5667]\n",
      "# 27000  손실 비용:  2267176.2\n",
      "- 배추 가격:  [2574.3052]\n",
      "# 27500  손실 비용:  2266894.0\n",
      "- 배추 가격:  [2574.959]\n",
      "# 28000  손실 비용:  2266613.0\n",
      "- 배추 가격:  [2575.565]\n",
      "# 28500  손실 비용:  2266332.0\n",
      "- 배추 가격:  [2576.094]\n",
      "# 29000  손실 비용:  2266052.0\n",
      "- 배추 가격:  [2576.584]\n",
      "# 29500  손실 비용:  2265772.0\n",
      "- 배추 가격:  [2577.0098]\n",
      "# 30000  손실 비용:  2265492.0\n",
      "- 배추 가격:  [2577.3867]\n",
      "# 30500  손실 비용:  2265212.8\n",
      "- 배추 가격:  [2577.7253]\n",
      "# 31000  손실 비용:  2264934.2\n",
      "- 배추 가격:  [2578.051]\n",
      "# 31500  손실 비용:  2264655.8\n",
      "- 배추 가격:  [2578.3013]\n",
      "# 32000  손실 비용:  2264377.0\n",
      "- 배추 가격:  [2578.5427]\n",
      "# 32500  손실 비용:  2264097.5\n",
      "- 배추 가격:  [2578.7837]\n",
      "# 33000  손실 비용:  2263819.0\n",
      "- 배추 가격:  [2579.0168]\n",
      "# 33500  손실 비용:  2263541.5\n",
      "- 배추 가격:  [2579.209]\n",
      "# 34000  손실 비용:  2263264.0\n",
      "- 배추 가격:  [2579.34]\n",
      "# 34500  손실 비용:  2262987.0\n",
      "- 배추 가격:  [2579.4688]\n",
      "# 35000  손실 비용:  2262709.2\n",
      "- 배추 가격:  [2579.597]\n",
      "# 35500  손실 비용:  2262433.0\n",
      "- 배추 가격:  [2579.7246]\n",
      "# 36000  손실 비용:  2262156.2\n",
      "- 배추 가격:  [2579.8525]\n",
      "# 36500  손실 비용:  2261879.8\n",
      "- 배추 가격:  [2579.9805]\n",
      "# 37000  손실 비용:  2261603.2\n",
      "- 배추 가격:  [2580.108]\n",
      "# 37500  손실 비용:  2261327.5\n",
      "- 배추 가격:  [2580.233]\n",
      "# 38000  손실 비용:  2261050.8\n",
      "- 배추 가격:  [2580.3528]\n",
      "# 38500  손실 비용:  2260774.5\n",
      "- 배추 가격:  [2580.4153]\n",
      "# 39000  손실 비용:  2260499.0\n",
      "- 배추 가격:  [2580.4531]\n",
      "# 39500  손실 비용:  2260223.0\n",
      "- 배추 가격:  [2580.4902]\n",
      "# 40000  손실 비용:  2259948.8\n",
      "- 배추 가격:  [2580.527]\n",
      "# 40500  손실 비용:  2259674.5\n",
      "- 배추 가격:  [2580.5613]\n",
      "# 41000  손실 비용:  2259399.5\n",
      "- 배추 가격:  [2580.594]\n",
      "# 41500  손실 비용:  2259125.5\n",
      "- 배추 가격:  [2580.6272]\n",
      "# 42000  손실 비용:  2258851.0\n",
      "- 배추 가격:  [2580.6602]\n",
      "# 42500  손실 비용:  2258577.0\n",
      "- 배추 가격:  [2580.6934]\n",
      "# 43000  손실 비용:  2258303.2\n",
      "- 배추 가격:  [2580.7263]\n",
      "# 43500  손실 비용:  2258029.2\n",
      "- 배추 가격:  [2580.76]\n",
      "# 44000  손실 비용:  2257755.5\n",
      "- 배추 가격:  [2580.7935]\n",
      "# 44500  손실 비용:  2257482.0\n",
      "- 배추 가격:  [2580.8274]\n",
      "# 45000  손실 비용:  2257208.5\n",
      "- 배추 가격:  [2580.8608]\n",
      "# 45500  손실 비용:  2256935.8\n",
      "- 배추 가격:  [2580.894]\n",
      "# 46000  손실 비용:  2256662.5\n",
      "- 배추 가격:  [2580.9277]\n",
      "# 46500  손실 비용:  2256389.5\n",
      "- 배추 가격:  [2580.963]\n",
      "# 47000  손실 비용:  2256116.8\n",
      "- 배추 가격:  [2580.9978]\n",
      "# 47500  손실 비용:  2255845.2\n",
      "- 배추 가격:  [2581.0312]\n",
      "# 48000  손실 비용:  2255573.8\n",
      "- 배추 가격:  [2581.0654]\n",
      "# 48500  손실 비용:  2255303.0\n",
      "- 배추 가격:  [2581.1028]\n",
      "# 49000  손실 비용:  2255031.5\n",
      "- 배추 가격:  [2581.1409]\n",
      "# 49500  손실 비용:  2254760.5\n",
      "- 배추 가격:  [2581.1812]\n",
      "# 50000  손실 비용:  2254489.8\n",
      "- 배추 가격:  [2581.2231]\n",
      "# 50500  손실 비용:  2254218.5\n",
      "- 배추 가격:  [2581.2651]\n",
      "# 51000  손실 비용:  2253948.0\n",
      "- 배추 가격:  [2581.3093]\n",
      "# 51500  손실 비용:  2253677.5\n",
      "- 배추 가격:  [2581.3555]\n",
      "# 52000  손실 비용:  2253407.0\n",
      "- 배추 가격:  [2581.401]\n",
      "# 52500  손실 비용:  2253136.8\n",
      "- 배추 가격:  [2581.4473]\n",
      "# 53000  손실 비용:  2252866.8\n",
      "- 배추 가격:  [2581.4946]\n",
      "# 53500  손실 비용:  2252597.0\n",
      "- 배추 가격:  [2581.5444]\n",
      "# 54000  손실 비용:  2252326.8\n",
      "- 배추 가격:  [2581.5942]\n",
      "# 54500  손실 비용:  2252057.5\n",
      "- 배추 가격:  [2581.6414]\n",
      "# 55000  손실 비용:  2251789.2\n",
      "- 배추 가격:  [2581.6855]\n",
      "# 55500  손실 비용:  2251520.8\n",
      "- 배추 가격:  [2581.7314]\n",
      "# 56000  손실 비용:  2251252.5\n",
      "- 배추 가격:  [2581.7795]\n",
      "# 56500  손실 비용:  2250984.8\n",
      "- 배추 가격:  [2581.828]\n",
      "# 57000  손실 비용:  2250716.5\n",
      "- 배추 가격:  [2581.8762]\n",
      "# 57500  손실 비용:  2250448.2\n",
      "- 배추 가격:  [2581.9246]\n",
      "# 58000  손실 비용:  2250180.8\n",
      "- 배추 가격:  [2581.9722]\n",
      "# 58500  손실 비용:  2249914.0\n",
      "- 배추 가격:  [2582.015]\n",
      "# 59000  손실 비용:  2249647.5\n",
      "- 배추 가격:  [2582.0596]\n",
      "# 59500  손실 비용:  2249381.0\n",
      "- 배추 가격:  [2582.11]\n",
      "# 60000  손실 비용:  2249115.0\n",
      "- 배추 가격:  [2582.1604]\n",
      "# 60500  손실 비용:  2248849.0\n",
      "- 배추 가격:  [2582.211]\n",
      "# 61000  손실 비용:  2248582.8\n",
      "- 배추 가격:  [2582.2515]\n",
      "# 61500  손실 비용:  2248316.5\n",
      "- 배추 가격:  [2582.285]\n",
      "# 62000  손실 비용:  2248051.0\n",
      "- 배추 가격:  [2582.318]\n",
      "# 62500  손실 비용:  2247785.2\n",
      "- 배추 가격:  [2582.3513]\n",
      "# 63000  손실 비용:  2247519.2\n",
      "- 배추 가격:  [2582.385]\n",
      "# 63500  손실 비용:  2247253.8\n",
      "- 배추 가격:  [2582.4187]\n",
      "# 64000  손실 비용:  2246988.5\n",
      "- 배추 가격:  [2582.4521]\n",
      "# 64500  손실 비용:  2246723.5\n",
      "- 배추 가격:  [2582.4858]\n",
      "# 65000  손실 비용:  2246458.2\n",
      "- 배추 가격:  [2582.5198]\n",
      "# 65500  손실 비용:  2246193.2\n",
      "- 배추 가격:  [2582.5535]\n",
      "# 66000  손실 비용:  2245928.2\n",
      "- 배추 가격:  [2582.588]\n",
      "# 66500  손실 비용:  2245663.8\n",
      "- 배추 가격:  [2582.6296]\n",
      "# 67000  손실 비용:  2245399.2\n",
      "- 배추 가격:  [2582.681]\n",
      "# 67500  손실 비용:  2245135.2\n",
      "- 배추 가격:  [2582.732]\n",
      "# 68000  손실 비용:  2244870.2\n",
      "- 배추 가격:  [2582.783]\n",
      "# 68500  손실 비용:  2244605.2\n",
      "- 배추 가격:  [2582.8335]\n",
      "# 69000  손실 비용:  2244341.5\n",
      "- 배추 가격:  [2582.8806]\n",
      "# 69500  손실 비용:  2244077.0\n",
      "- 배추 가격:  [2582.9258]\n",
      "# 70000  손실 비용:  2243813.0\n",
      "- 배추 가격:  [2582.9714]\n",
      "# 70500  손실 비용:  2243549.0\n",
      "- 배추 가격:  [2583.0125]\n",
      "# 71000  손실 비용:  2243285.5\n",
      "- 배추 가격:  [2583.0525]\n",
      "# 71500  손실 비용:  2243021.2\n",
      "- 배추 가격:  [2583.0925]\n",
      "# 72000  손실 비용:  2242758.2\n",
      "- 배추 가격:  [2583.1301]\n",
      "# 72500  손실 비용:  2242495.0\n",
      "- 배추 가격:  [2583.1648]\n",
      "# 73000  손실 비용:  2242233.0\n",
      "- 배추 가격:  [2583.1956]\n",
      "# 73500  손실 비용:  2241972.2\n",
      "- 배추 가격:  [2583.2231]\n",
      "# 74000  손실 비용:  2241711.0\n",
      "- 배추 가격:  [2583.2485]\n",
      "# 74500  손실 비용:  2241450.8\n",
      "- 배추 가격:  [2583.2705]\n",
      "# 75000  손실 비용:  2241190.2\n",
      "- 배추 가격:  [2583.2927]\n",
      "# 75500  손실 비용:  2240930.0\n",
      "- 배추 가격:  [2583.3147]\n",
      "# 76000  손실 비용:  2240669.5\n",
      "- 배추 가격:  [2583.337]\n",
      "# 76500  손실 비용:  2240409.2\n",
      "- 배추 가격:  [2583.359]\n",
      "# 77000  손실 비용:  2240149.5\n",
      "- 배추 가격:  [2583.3765]\n",
      "# 77500  손실 비용:  2239889.5\n",
      "- 배추 가격:  [2583.3933]\n",
      "# 78000  손실 비용:  2239629.5\n",
      "- 배추 가격:  [2583.4104]\n",
      "# 78500  손실 비용:  2239370.0\n",
      "- 배추 가격:  [2583.4268]\n",
      "# 79000  손실 비용:  2239109.8\n",
      "- 배추 가격:  [2583.4436]\n",
      "# 79500  손실 비용:  2238850.5\n",
      "- 배추 가격:  [2583.4602]\n",
      "# 80000  손실 비용:  2238591.2\n",
      "- 배추 가격:  [2583.4773]\n",
      "# 80500  손실 비용:  2238331.2\n",
      "- 배추 가격:  [2583.4897]\n",
      "# 81000  손실 비용:  2238072.2\n",
      "- 배추 가격:  [2583.5015]\n",
      "# 81500  손실 비용:  2237813.5\n",
      "- 배추 가격:  [2583.5127]\n",
      "# 82000  손실 비용:  2237554.2\n",
      "- 배추 가격:  [2583.5244]\n",
      "# 82500  손실 비용:  2237296.0\n",
      "- 배추 가격:  [2583.5356]\n",
      "# 83000  손실 비용:  2237036.8\n",
      "- 배추 가격:  [2583.5474]\n",
      "# 83500  손실 비용:  2236778.2\n",
      "- 배추 가격:  [2583.5588]\n",
      "# 84000  손실 비용:  2236519.5\n",
      "- 배추 가격:  [2583.5703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 84500  손실 비용:  2236261.0\n",
      "- 배추 가격:  [2583.5815]\n",
      "# 85000  손실 비용:  2236002.8\n",
      "- 배추 가격:  [2583.5928]\n",
      "# 85500  손실 비용:  2235743.8\n",
      "- 배추 가격:  [2583.5994]\n",
      "# 86000  손실 비용:  2235485.8\n",
      "- 배추 가격:  [2583.6057]\n",
      "# 86500  손실 비용:  2235227.5\n",
      "- 배추 가격:  [2583.6118]\n",
      "# 87000  손실 비용:  2234970.0\n",
      "- 배추 가격:  [2583.6177]\n",
      "# 87500  손실 비용:  2234712.2\n",
      "- 배추 가격:  [2583.624]\n",
      "# 88000  손실 비용:  2234454.5\n",
      "- 배추 가격:  [2583.657]\n",
      "# 88500  손실 비용:  2234197.0\n",
      "- 배추 가격:  [2583.691]\n",
      "# 89000  손실 비용:  2233939.2\n",
      "- 배추 가격:  [2583.725]\n",
      "# 89500  손실 비용:  2233682.2\n",
      "- 배추 가격:  [2583.7595]\n",
      "# 90000  손실 비용:  2233425.2\n",
      "- 배추 가격:  [2583.794]\n",
      "# 90500  손실 비용:  2233170.5\n",
      "- 배추 가격:  [2583.8274]\n",
      "# 91000  손실 비용:  2232915.5\n",
      "- 배추 가격:  [2583.861]\n",
      "# 91500  손실 비용:  2232661.2\n",
      "- 배추 가격:  [2583.8953]\n",
      "# 92000  손실 비용:  2232407.2\n",
      "- 배추 가격:  [2583.929]\n",
      "# 92500  손실 비용:  2232152.8\n",
      "- 배추 가격:  [2583.963]\n",
      "# 93000  손실 비용:  2231899.2\n",
      "- 배추 가격:  [2583.9968]\n",
      "# 93500  손실 비용:  2231645.2\n",
      "- 배추 가격:  [2584.0308]\n",
      "# 94000  손실 비용:  2231392.0\n",
      "- 배추 가격:  [2584.065]\n",
      "# 94500  손실 비용:  2231137.0\n",
      "- 배추 가격:  [2584.099]\n",
      "# 95000  손실 비용:  2230883.8\n",
      "- 배추 가격:  [2584.1333]\n",
      "# 95500  손실 비용:  2230630.2\n",
      "- 배추 가격:  [2584.167]\n",
      "# 96000  손실 비용:  2230376.5\n",
      "- 배추 가격:  [2584.201]\n",
      "# 96500  손실 비용:  2230123.5\n",
      "- 배추 가격:  [2584.2356]\n",
      "# 97000  손실 비용:  2229870.5\n",
      "- 배추 가격:  [2584.2705]\n",
      "# 97500  손실 비용:  2229617.8\n",
      "- 배추 가격:  [2584.3047]\n",
      "# 98000  손실 비용:  2229364.8\n",
      "- 배추 가격:  [2584.3396]\n",
      "# 98500  손실 비용:  2229112.2\n",
      "- 배추 가격:  [2584.3738]\n",
      "# 99000  손실 비용:  2228859.2\n",
      "- 배추 가격:  [2584.4084]\n",
      "# 99500  손실 비용:  2228606.8\n",
      "- 배추 가격:  [2584.443]\n",
      "# 100000  손실 비용:  2228354.2\n",
      "- 배추 가격:  [2584.4775]\n"
     ]
    }
   ],
   "source": [
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()                            # 세션을 생성합니다.\n",
    "sess.run(tf.global_variables_initializer())    # 글로벌 변수를 초기화합니다.\n",
    "\n",
    "# 학습을 수행합니다.\n",
    "for step in range(100001):\n",
    "    cost_, hypo_, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 500 == 0:\n",
    "        print(\"#\", step, \" 손실 비용: \", cost_)\n",
    "        print(\"- 배추 가격: \", hypo_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 모델을 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델을 저장합니다.\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"./saved.cpkt\")\n",
    "print('학습된 모델을 저장했습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사하강법 적용하기 (모두의 딥러닝)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "def plot_hour2grade(x, y, xline, yline):\n",
    "    \"\"\" x, y의 값들을 그래프로 출력 \"\"\"\n",
    "    plt.figure()  \n",
    "    plt.plot(x, y, '^r')  \n",
    "    plt.plot(xline, yline)\n",
    "    plt.title('Hours vs. Grade')\n",
    "    plt.xlabel('hours')\n",
    "    plt.ylabel('grades')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 03_Gradient_Descent.py\n",
    "import tensorflow as tf\n",
    "\n",
    "# x, y의 데이터 값\n",
    "data = [[2, 81], [4, 93], [6, 91], [8, 97]]\n",
    "x_data = [x_row[0] for x_row in data]\n",
    "y_data = [y_row[1] for y_row in data]\n",
    "\n",
    "# 기울기 a와 y 절편 b의 값을 임의로 정한다.\n",
    "# 단, 기울기의 범위는 0 ~ 10 사이이며 y 절편은 0 ~ 100 사이에서 변하게 한다.\n",
    "a = tf.Variable(tf.random_uniform([1], 0, 10, dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100, dtype = tf.float64, seed = 0))\n",
    "\n",
    "# y에 대한 일차 방정식 ax+b의 식을 세운다.\n",
    "y = a * x_data + b\n",
    "\n",
    "# 텐서플로 RMSE 함수\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square( y - y_data )))\n",
    "\n",
    "# 학습률 값\n",
    "learning_rate = 0.1\n",
    "\n",
    "# RMSE 값을 최소로 하는 값 찾기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "# 텐서플로를 이용한 학습\n",
    "with tf.Session() as sess:\n",
    "    # 변수 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 2001번 실행(0번 째를 포함하므로)\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_decent)\n",
    "        # 100번마다 결과 출력\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE = %.04f, 기울기 a = %.4f, y 절편 b = %.4f\" % (step,sess.run(rmse),sess.run(a),sess.run(b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0000\n",
    "x=[2, 4, 6, 8]\n",
    "y=[81, 93, 91, 97]\n",
    "\n",
    "a = 2.3000\n",
    "b = 79.0000\n",
    "# code to plot the line y = a x + b\n",
    "xline = np.arange(1, 10, .5)\n",
    "yline = a * xline + b\n",
    "plot_hour2grade(x, y, xline, yline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 선형 회귀 (모두의 딥러닝)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 04_Multi-Linear-Regression.py\n",
    "import tensorflow as tf\n",
    "\n",
    "# x1, x2, y의 데이터 값\n",
    "\n",
    "data = [[2, 0, 81], [4, 4, 93], [6, 2, 91], [8, 3, 97]]\n",
    "x1 = [x_row1[0] for x_row1 in data]\n",
    "x2 = [x_row2[1] for x_row2 in data] # 새로 추가되는 값\n",
    "y_data = [y_row[2] for y_row in data]\n",
    "\n",
    "# 기울기 a와 y절편 b의 값을 임의로 정함. 단 기울기의 범위는 0-10 사이, y 절편은 0-100사이에서 변하게 함\n",
    "a1 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "a2 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100, dtype=tf.float64, seed=0))\n",
    "\n",
    "# 새로운 방정식\n",
    "y = a1 * x1 + a2 * x2+ b\n",
    "\n",
    "# 텐서플로 RMSE 함수\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square( y - y_data )))\n",
    "\n",
    "# 학습률 값\n",
    "learning_rate = 0.1\n",
    "\n",
    "# RMSE 값을 최소로 하는 값 찾기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "# 학습이 진행되는 부분\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_decent)\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE = %.04f, 기울기 a1 = %.4f, 기울기 a2 = %.4f, y절편 b = %.4f\" % (step,sess.run(rmse),sess.run(a1),sess.run(a2),sess.run(b)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 선형 회귀 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 05_3D_Graph.py\n",
    "import numpy as np\n",
    "import statsmodels.api as statm\n",
    "import statsmodels.formula.api as statfa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "data = [[2, 0, 81], [4, 4, 93], [6, 2, 91], [8, 3, 97]]\n",
    "X = [i[0:2] for i in data]\n",
    "Y = [i[2] for i in data]\n",
    "\n",
    "X_1=statm.add_constant(X)\n",
    "results=statm.OLS(Y,X_1).fit()\n",
    "\n",
    "hour_class=pd.DataFrame(X,columns=['study_hours','private_class'])\n",
    "hour_class['Score']=pd.Series(Y)\n",
    "\n",
    "model = statfa.ols(formula='Score ~ study_hours + private_class', data=hour_class)\n",
    "\n",
    "results_formula = model.fit()\n",
    "\n",
    "a, b = np.meshgrid(np.linspace(hour_class.study_hours.min(),hour_class.study_hours.max(),100),\n",
    "                   np.linspace(hour_class.private_class.min(),hour_class.private_class.max(),100))\n",
    "\n",
    "X_ax = pd.DataFrame({'study_hours': a.ravel(), 'private_class': b.ravel()})\n",
    "fittedY=results_formula.predict(exog=X_ax)\n",
    "fig = plt.figure()\n",
    "\n",
    "graph = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "graph.scatter(hour_class['study_hours'],hour_class['private_class'],hour_class['Score'],\n",
    "              c='blue',marker='o', alpha=1)\n",
    "graph.plot_surface(a,b,fittedY.values.reshape(a.shape),\n",
    "                   rstride=1, cstride=1, color='none', alpha=0.4)\n",
    "graph.set_xlabel('study_hours')\n",
    "graph.set_ylabel('private_class')\n",
    "graph.set_zlabel('Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression & Gradient Descent Example (동빈나)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "xData = [1, 2, 3, 4, 5, 6, 7]\n",
    "yData = [25000, 55000, 75000, 110000, 128000, 155000, 180000]\n",
    "W = tf.Variable(tf.random_uniform([1], -100, 100))\n",
    "b = tf.Variable(tf.random_uniform([1], -100, 100))\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "H = W * X + b\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "a = tf.Variable(0.01)   # set learning rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in  range(5001):\n",
    "    sess.run(train, feed_dict={X:xData, Y:yData})\n",
    "    if i % 500 == 0:\n",
    "        print(i, sess.run(cost, feed_dict={X:xData, Y:yData}), sess.run(W), sess.run(b))\n",
    "\n",
    "print(sess.run(H, feed_dict={X: [8]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
